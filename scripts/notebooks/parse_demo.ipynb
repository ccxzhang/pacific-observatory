{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9520d332",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../../\")\n",
    "import math\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pdfplumber\n",
    "import tabula\n",
    "import PyPDF2\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12e885c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_path = os.getcwd() + \"/data/tourism/vanuatu/2013-TM-06-June_News.pdf\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c128ce",
   "metadata": {},
   "source": [
    "## Tonga \n",
    "### Table 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "999ac755",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tonga_lsts = os.listdir(\"data/tourism/tonga\")\n",
    "filepaths = [os.getcwd() + \"/data/tourism/tonga/\" +\n",
    "             path for path in tonga_lsts if \"Dec\" in path]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "8c77190c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def locate_table(filepath: str,\n",
    "                 search_string: str,\n",
    "                 ignore_case=False):\n",
    "\n",
    "    search_lst = list()\n",
    "    reader = PyPDF2.PdfReader(filepath)\n",
    "\n",
    "    for page_num, page in enumerate(reader.pages):\n",
    "        try:\n",
    "            page_text = page.extract_text()\n",
    "            hits = None\n",
    "            if ignore_case == False:\n",
    "                hits = re.search(search_string, page_text.lower())\n",
    "            else:\n",
    "                hits = re.search(\n",
    "                    search_string, page_text.lower(), re.IGNORECASE)\n",
    "\n",
    "            if hits:\n",
    "                search_lst.append(page_num+1)\n",
    "        except:\n",
    "            pass\n",
    "    return {\"table_loc\": search_lst}\n",
    "\n",
    "\n",
    "def load_pdf(filepath: str,\n",
    "             search_string: str,\n",
    "             table_page: int,\n",
    "             table_seq=0):\n",
    "\n",
    "    table_loc = locate_table(filepath, search_string,\n",
    "                             ignore_case=True)[\"table_loc\"]\n",
    "    if len(table_loc) != 0:\n",
    "        table_page = table_loc[-1]\n",
    "        dfs = tabula.read_pdf(filepath, pages=table_page, stream=True)\n",
    "        if len(dfs) > 1:\n",
    "            print(f\"The page has {len(dfs)} tables.\")\n",
    "            df = dfs[table_seq]\n",
    "\n",
    "        else:\n",
    "            df = dfs[0]\n",
    "            df.columns = df.iloc[0, :].to_list()\n",
    "    else:\n",
    "        dfs = tabula.read_pdf(filepath, pages=\"all\", stream=True)\n",
    "        df = dfs[table_page]\n",
    "        df.columns = df.iloc[0, :].to_list()\n",
    "\n",
    "    df = df.iloc[1:].reset_index().drop(\"index\", axis=1)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def split_time(df: pd.DataFrame,\n",
    "               time_var: str):\n",
    "\n",
    "    year_idx, month_idx = list(), list()\n",
    "    for idx in df.index:\n",
    "        if (str(df[time_var][idx]).isdigit() == True):\n",
    "            year_idx.append(idx)\n",
    "        else:\n",
    "            month_idx.append(idx)\n",
    "\n",
    "    latest_year_idx = max(year_idx)\n",
    "\n",
    "    return latest_year_idx, year_idx, month_idx\n",
    "\n",
    "\n",
    "def detect_year(series: pd.Series):\n",
    "    nacheck = pd.isna(series)\n",
    "    start_year = int(series[nacheck == False][0])\n",
    "    return start_year\n",
    "\n",
    "\n",
    "def generate_time(df: pd.DataFrame,\n",
    "                  start_year: int):\n",
    "\n",
    "    years = [start_year + idx // 12 for idx in df.index]\n",
    "    df[\"Year\"] = years\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def remove_separator(df: pd.DataFrame):\n",
    "\n",
    "    colnames = df.columns\n",
    "    for col in colnames:\n",
    "        try:\n",
    "            if df[col].dtype == \"O\":\n",
    "                df[col] = (df[col].str.replace(\",\", \"\")\n",
    "                                  .str.replace(\"-\", \"\")\n",
    "                                  .str.replace(\"(\", \"\")\n",
    "                                  .str.replace(\")\", \"\")\n",
    "                                  .str.replace(\" \", \"\"))\n",
    "        except:\n",
    "            print(col, \"might have an error.\")\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def separate_data(df: pd.DataFrame,\n",
    "                  var: str,\n",
    "                  split_rule: str):\n",
    "\n",
    "    splited_lst = var.split(split_rule)\n",
    "    var_number = len(splited_lst)\n",
    "\n",
    "    obj = dict()\n",
    "    for i in range(var_number):\n",
    "        obj[str(splited_lst[i])] = []\n",
    "\n",
    "    for i in df[var]:\n",
    "        elems = i.split(\" \")\n",
    "        length = len(elems)\n",
    "        if length == var_number:\n",
    "            idx, var = 0, list(obj.keys())\n",
    "            while idx < length:\n",
    "                key, val = var[idx], elems[idx]\n",
    "                obj[key].append(val)\n",
    "                idx += 1\n",
    "\n",
    "        elif length < var_number:\n",
    "            idx, var = 0, list(obj.keys())\n",
    "            while idx < length and len(elems) != 0:\n",
    "                key, val = var[idx], elems[idx].split(\" \")[0]\n",
    "                obj[key].append(val)\n",
    "                elems = i.replace(val, \"\").strip()\n",
    "                idx += 1\n",
    "            else:\n",
    "                key, val = var[idx], 0\n",
    "                obj[key].append(val)\n",
    "                idx += 1\n",
    "\n",
    "        else:\n",
    "            idx, var = 0, list(obj.keys())\n",
    "            while idx < var_number:\n",
    "                key, val = var[idx], elems[idx]\n",
    "                obj[key].append(val)\n",
    "                idx += 1\n",
    "            else:\n",
    "                key, val = var[-1], elems[idx]\n",
    "                prev_val = obj[key][-1]\n",
    "                obj[key][-1] = prev_val + val\n",
    "\n",
    "    for i in range(var_number):\n",
    "        df[str(splited_lst[i])] = obj[list(obj.keys())[i]]\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def check_quality(df: pd.DataFrame,\n",
    "                  exclude_vars: list,\n",
    "                  sum_var: str):\n",
    "\n",
    "    new_df = df.iloc[:, ~df.columns.isin(exclude_vars)]\n",
    "    checked_vars = new_df.columns[~new_df.columns.isin([sum_var])].to_list()\n",
    "\n",
    "    for idx in new_df.index:\n",
    "        row_sum = 0\n",
    "        for var in checked_vars:\n",
    "            val = new_df[var][idx]\n",
    "            if math.isnan(float(val)) != True:\n",
    "                row_sum += float(val)\n",
    "            else:\n",
    "                row_sum += 0\n",
    "        if float(new_df[sum_var][idx]) == row_sum:\n",
    "            pass\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dee0f9aa",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/czhang/Desktop/PO-Tourism/data/tonga/Migration-Report-Dec-2017.pdf\n",
      "The file starts from 2013.\n",
      "     Period Yacht Total   Air  Ship  Year\n",
      "0   January     9  3858  2927   922  2013\n",
      "1  February     2  3933  2621  1310  2013\n",
      "2     March    11  3434  2797   626  2013\n",
      "3     April    50  6343  3088  3205  2013\n",
      "4       May   328  4293  3965     0  2013\n",
      "/Users/czhang/Desktop/PO-Tourism/data/tonga/Migration-December-Report-2019.pdf\n",
      "The file starts from 2018.\n",
      "   Migration-December-Report-2019 could go wrong!\n",
      "  Period Yacht Total   Air  Ship  Year\n",
      "0    Jan     7  7640  4294  3346  2018\n",
      "1    Feb     0  3856  2336  1520  2018\n",
      "2    Mar    14  5911  2835  3062  2018\n",
      "3    Apr    34  5477  3099  2344  2018\n",
      "4    May   166  5141  4348   627  2018\n",
      "/Users/czhang/Desktop/PO-Tourism/data/tonga/12-December-Migration-Report-2014.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Got stderr: Nov 21, 2022 5:06:57 PM org.apache.pdfbox.pdmodel.PDDocument importPage\n",
      "WARNING: inherited resources of source document are not imported to destination page\n",
      "Nov 21, 2022 5:06:57 PM org.apache.pdfbox.pdmodel.PDDocument importPage\n",
      "WARNING: call importedPage.setResources(page.getResources()) to do this\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file starts from 2010.\n",
      "     Period Yacht Total   Air  Ship  Year\n",
      "0   January     4  3808  3158   646  2010\n",
      "1  February     5  2384  2379     0  2010\n",
      "2     March     5  3992  3134   853  2010\n",
      "3     April    30  5650  2818  2802  2010\n",
      "4       May   177  9150  3670  5303  2010\n",
      "/Users/czhang/Desktop/PO-Tourism/data/tonga/12-December-Migration-Report-2015.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Got stderr: Nov 21, 2022 5:07:04 PM org.apache.pdfbox.pdmodel.PDDocument importPage\n",
      "WARNING: inherited resources of source document are not imported to destination page\n",
      "Nov 21, 2022 5:07:04 PM org.apache.pdfbox.pdmodel.PDDocument importPage\n",
      "WARNING: call importedPage.setResources(page.getResources()) to do this\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file starts from 2010.\n",
      "     Period Yacht Total   Air  Ship  Year\n",
      "0   January     4  3808  3158   646  2010\n",
      "1  February     5  2384  2379     0  2010\n",
      "2     March     5  3992  3134   853  2010\n",
      "3     April    30  5650  2818  2802  2010\n",
      "4       May   177  9150  3670  5303  2010\n",
      "/Users/czhang/Desktop/PO-Tourism/data/tonga/Migration-December-Report-2020.pdf\n",
      "The file starts from 2018.\n",
      "   Migration-December-Report-2020 could go wrong!\n",
      "  Period Yacht Total   Air  Ship  Year\n",
      "0    Jan     7  7640  4294  3346  2018\n",
      "1    Feb     0  3856  2336  1520  2018\n",
      "2    Mar    14  5911  2835  3062  2018\n",
      "3    Apr    34  5477  3099  2344  2018\n",
      "4    May   166  5141  4348   627  2018\n",
      "/Users/czhang/Desktop/PO-Tourism/data/tonga/12-December-Migration-Report-2013.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Got stderr: Nov 21, 2022 5:07:15 PM org.apache.pdfbox.pdmodel.PDDocument importPage\n",
      "WARNING: inherited resources of source document are not imported to destination page\n",
      "Nov 21, 2022 5:07:15 PM org.apache.pdfbox.pdmodel.PDDocument importPage\n",
      "WARNING: call importedPage.setResources(page.getResources()) to do this\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file starts from 2010.\n",
      "     Period Yacht Total   Air  Ship  Year\n",
      "0   January     4  3808  3158   646  2010\n",
      "1  February     5  2384  2379     0  2010\n",
      "2     March     5  3992  3134   853  2010\n",
      "3     April    30  5650  2818  2802  2010\n",
      "4       May   177  9150  3670  5303  2010\n",
      "/Users/czhang/Desktop/PO-Tourism/data/tonga/12-Migration-Report-Dec-2016.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Got stderr: Nov 21, 2022 5:07:23 PM org.apache.pdfbox.pdmodel.PDDocument importPage\n",
      "WARNING: inherited resources of source document are not imported to destination page\n",
      "Nov 21, 2022 5:07:23 PM org.apache.pdfbox.pdmodel.PDDocument importPage\n",
      "WARNING: call importedPage.setResources(page.getResources()) to do this\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file starts from 2011.\n",
      "     Period Yacht Total   Air  Ship  Year\n",
      "0   January     2  2846  2844   NaN  2011\n",
      "1  February    14  9163  2302  6847  2011\n",
      "2     March    16  3900  2477  1407  2011\n",
      "3     April    37  6595  3520  3038  2011\n",
      "4       May   250  4062  3812     0  2011\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Period</th>\n",
       "      <th>Air</th>\n",
       "      <th>Ship</th>\n",
       "      <th>Yacht</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010</td>\n",
       "      <td>January</td>\n",
       "      <td>3158</td>\n",
       "      <td>646</td>\n",
       "      <td>4</td>\n",
       "      <td>3808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010</td>\n",
       "      <td>December</td>\n",
       "      <td>6493</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>6506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010</td>\n",
       "      <td>November</td>\n",
       "      <td>3569</td>\n",
       "      <td>1386</td>\n",
       "      <td>126</td>\n",
       "      <td>5081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010</td>\n",
       "      <td>October</td>\n",
       "      <td>3467</td>\n",
       "      <td>0</td>\n",
       "      <td>352</td>\n",
       "      <td>3819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010</td>\n",
       "      <td>August</td>\n",
       "      <td>4216</td>\n",
       "      <td>0</td>\n",
       "      <td>246</td>\n",
       "      <td>4462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>2020</td>\n",
       "      <td>Apr</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>2020</td>\n",
       "      <td>Mar</td>\n",
       "      <td>1259</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>2020</td>\n",
       "      <td>Feb</td>\n",
       "      <td>3008</td>\n",
       "      <td>1678</td>\n",
       "      <td>6</td>\n",
       "      <td>4692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>2020</td>\n",
       "      <td>Jul</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>2020</td>\n",
       "      <td>Jan</td>\n",
       "      <td>4665</td>\n",
       "      <td>852</td>\n",
       "      <td>0</td>\n",
       "      <td>5517</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>141 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Year    Period   Air  Ship Yacht Total\n",
       "0    2010   January  3158   646     4  3808\n",
       "1    2010  December  6493     0    13  6506\n",
       "2    2010  November  3569  1386   126  5081\n",
       "3    2010   October  3467     0   352  3819\n",
       "4    2010    August  4216     0   246  4462\n",
       "..    ...       ...   ...   ...   ...   ...\n",
       "136  2020       Apr     0     0     0     0\n",
       "137  2020       Mar  1259     0     0  1259\n",
       "138  2020       Feb  3008  1678     6  4692\n",
       "139  2020       Jul     1     0     0     1\n",
       "140  2020       Jan  4665   852     0  5517\n",
       "\n",
       "[141 rows x 6 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "months = pd.DataFrame()\n",
    "\n",
    "for file in filepaths[:-1]:\n",
    "    print(file)\n",
    "\n",
    "    df = load_pdf(file, \"Monthly Arrival and Departure\", table_page=-5)\n",
    "    latest_year, year_idx, month_idx = split_time(df, \"Period\")\n",
    "    month = df.iloc[month_idx, 0:4]\n",
    "    start_year = detect_year(df.iloc[month_idx].iloc[0])\n",
    "\n",
    "    month = (month.dropna(how=\"all\").reset_index()\n",
    "             .drop(\"index\", axis=1))\n",
    "\n",
    "    print(f\"The file starts from {start_year}.\")\n",
    "\n",
    "    month = separate_data(month, \"Air Ship\", \" \").drop(\"Air Ship\", axis=1)\n",
    "    month = remove_separator(month)\n",
    "    month = month.replace(r'^\\s*$', 0, regex=True)\n",
    "\n",
    "    if check_quality(month, [\"Period\", \"Year\"], \"Total\") == False:\n",
    "        name = file.split(\"/\")[-1].split(\".\")[0]\n",
    "        print(\"  \", name, \"could go wrong!\")\n",
    "\n",
    "    generate_time(month, start_year)\n",
    "    print(month.head(5))\n",
    "    months = pd.concat([months, month], axis=0)\n",
    "    \n",
    "months = (months[[\"Year\", \"Period\", \"Air\", \"Ship\", \"Yacht\", \"Total\"]]\n",
    "          .drop_duplicates()\n",
    "          .sort_values(by=\"Year\")\n",
    "          .reset_index()\n",
    "          .drop(\"index\", axis=1))\n",
    "\n",
    "months"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8acd174b",
   "metadata": {},
   "source": [
    "## Vanuatu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "449e81bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_path = os.getcwd() + \"/data/tourism/vanuatu/2014-TM-12-December-News.pdf\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb36d759",
   "metadata": {},
   "source": [
    "### Visitor Arrivals by Purpose of Visit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "51eaa2e5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = load_pdf(pdf_path, \"Visitor Arrivals by Purpose of Visit\", 6)\n",
    "df.columns = df.iloc[0]\n",
    "\n",
    "df = df.dropna(thresh=4, axis=1).replace(\"-\", 0)\n",
    "df = df.iloc[3:].reset_index().drop(\"index\", axis=1)\n",
    "\n",
    "splited = df[\"Conferences Stop Over\"].str.split(\" \", n=1, expand=True)\n",
    "splited.columns = [\"Conference\", \"Stopover\"]\n",
    "df = pd.concat([df, splited], axis=1)\n",
    "df = remove_separator(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c2b14940",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "vu_lsts = os.listdir(\"data/tourism/vanuatu\")\n",
    "dec_lst = [file for file in vu_lsts if \"Dec\" in file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5757a6ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tou12_December_News_2005.pdf has started\n",
      "nan might have an error.\n",
      "nan might have an error.\n",
      "Other might have an error.\n",
      "nan might have an error.\n",
      "nan might have an error.\n",
      "Other might have an error.\n",
      "  Tou12_December_News_2005.pdf does not find Année or Mois column.\n",
      "Tou12_December_News_2004.pdf has started\n",
      "nan might have an error.\n",
      "nan might have an error.\n",
      "Other might have an error.\n",
      "nan might have an error.\n",
      "nan might have an error.\n",
      "Other might have an error.\n",
      "  Tou12_December_News_2004.pdf does not find Année or Mois column.\n",
      "Tou12_December_News_2007.pdf has started\n",
      "nan might have an error.\n",
      "nan might have an error.\n",
      "nan might have an error.\n",
      "nan might have an error.\n",
      "  Tou12_December_News_2007.pdf does not find Année or Mois column.\n",
      "IAS_12_December_2015.pdf has started\n",
      "2012-TM-12-December_News.pdf has started\n",
      "  2012-TM-12-December_News.pdf does not find Année or Mois column.\n",
      "IAS_12_December_2016.pdf has started\n",
      "IVA_12_December_2021.pdf has started\n",
      "2014-TM-12-December-News.pdf has started\n",
      "2011-TM-12-December_News.pdf has started\n",
      "  2011-TM-12-December_News.pdf does not find Année or Mois column.\n",
      "2013-TM-12-December_News.pdf has started\n",
      "Tou12_December_2006.pdf has started\n",
      "nan might have an error.\n",
      "nan might have an error.\n",
      "Other might have an error.\n",
      "nan might have an error.\n",
      "nan might have an error.\n",
      "Other might have an error.\n",
      "  Tou12_December_2006.pdf does not find Année or Mois column.\n",
      "TM12_December_2009_News.pdf has started\n",
      "nan might have an error.\n",
      "nan might have an error.\n",
      "non might have an error.\n",
      "nan might have an error.\n",
      "nan might have an error.\n",
      "  TM12_December_2009_News.pdf does not find Année or Mois column.\n",
      "TM12_December_2008_News.pdf has started\n",
      "nan might have an error.\n",
      "nan might have an error.\n",
      "nan might have an error.\n",
      "nan might have an error.\n",
      "  TM12_December_2008_News.pdf does not find Année or Mois column.\n",
      "IVA_12_December-English_2019.pdf has started\n",
      "IAS_12_December_2018.pdf has started\n",
      "IAS_12_Dececember_2017.pdf has started\n",
      "IVA_12_Dec_2020.pdf has started\n"
     ]
    }
   ],
   "source": [
    "error_dict = {\n",
    "    \"file\": [],\n",
    "    \"reason\": []\n",
    "}\n",
    "\n",
    "\n",
    "for file in dec_lst:\n",
    "    if \".pdf\" in file and \"2010\" not in file:\n",
    "\n",
    "        print(f\"{file} has started\")\n",
    "        filepath = os.getcwd() + \"/data/tourism/vanuatu/\" + file\n",
    "\n",
    "        df = load_pdf(filepath, \"Visitor Arrivals by Purpose of Visit\", 6)\n",
    "        df.columns = df.iloc[0]\n",
    "\n",
    "        df = df.dropna(thresh=4, axis=1).replace(\"-\", 0)\n",
    "        df = df.iloc[3:].reset_index().drop(\"index\", axis=1)\n",
    "\n",
    "        try:\n",
    "            col_lst = df.columns.to_list()\n",
    "            stored_splited = [\"Business, Stop\",\n",
    "                              \"Cruiseship Other\", \"Conferences Stop Over\"]\n",
    "\n",
    "            for idx, val in enumerate(col_lst):\n",
    "                if type(val) == str and val in stored_splited:\n",
    "                    if val == \"Business, Stop\":\n",
    "                        separate_data(df, \"Business, Stop\", \",\")\n",
    "\n",
    "                    elif val == \"Conferences Stop Over\":\n",
    "                        splited = df[val].str.split(\" \", n=1, expand=True)\n",
    "\n",
    "                        if len(splited.columns) == 2:\n",
    "                            splited.columns = [\n",
    "                                val.split(\" \")[0], val.split(\" \")[-1]]\n",
    "                            df = pd.concat([df, splited], axis=1)\n",
    "\n",
    "                        else:\n",
    "                            print(f\"{file} has incompatible column.\")\n",
    "                            error_dict[\"file\"].append(file)\n",
    "                            error_dict[\"reason\"].append(\"Incompatible Column\")\n",
    "\n",
    "                    else:\n",
    "                        splited = df[val].str.split(\" \", n=2, expand=True)\n",
    "\n",
    "                        if len(splited.columns) == 2:\n",
    "                            splited.columns = val.split(\" \")\n",
    "                            df = pd.concat([df, splited], axis=1)\n",
    "                        else:\n",
    "                            print(\"Incompatible Column\")\n",
    "                            error_dict[\"file\"].append(file)\n",
    "                            error_dict[\"reason\"].append(\"Incompatible Column\")\n",
    "\n",
    "            df = remove_separator(df)\n",
    "\n",
    "            try:\n",
    "                df = df.drop([\"Conferences Stop Over\",\n",
    "                             \"Année\", \"Mois\"], axis=1)\n",
    "\n",
    "                if \"Holidays\" in df.columns:\n",
    "                    df[\"Holidays\"] = df[\"Holidays\"].str.replace(\" \", \"\")\n",
    "                    saved_path = os.getcwd() + \"/data/tourism/vanuatu/temp/\" + \\\n",
    "                        file.split(\".\")[0] + \".csv\"\n",
    "                    df.to_csv(saved_path, encoding=\"utf-8\")\n",
    "\n",
    "                else:\n",
    "                    print(\"  Holidays column not found.\")\n",
    "                    error_dict[\"file\"].append(file)\n",
    "                    error_dict[\"reason\"].append(\"Holidays column not found.\")\n",
    "\n",
    "            except:\n",
    "                print(f\"  {file} does not find Année or Mois column.\")\n",
    "                error_dict[\"file\"].append(file)\n",
    "                error_dict[\"reason\"].append(\"Année or Mois column not found.\")\n",
    "\n",
    "        except:\n",
    "            error_dict[\"file\"].append(file)\n",
    "            error_dict[\"reason\"].append(\"Column Error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b2a4536f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/czhang/Desktop/pacific-observatory/data/tourism/vanuatu/temp/IVA_12_December-English_2019.csv passed the quality check.\n",
      "/Users/czhang/Desktop/pacific-observatory/data/tourism/vanuatu/temp/IAS_12_December_2018.csv passed the quality check.\n",
      "/Users/czhang/Desktop/pacific-observatory/data/tourism/vanuatu/temp/IAS_12_Dececember_2017.csv passed the quality check.\n",
      "/Users/czhang/Desktop/pacific-observatory/data/tourism/vanuatu/temp/IVA_12_Dec_2020.csv fails to pass the quality check.\n",
      "/Users/czhang/Desktop/pacific-observatory/data/tourism/vanuatu/temp/2013-TM-12-December_News.csv passed the quality check.\n",
      "/Users/czhang/Desktop/pacific-observatory/data/tourism/vanuatu/temp/IVA_12_December_2021.csv fails to pass the quality check.\n",
      "/Users/czhang/Desktop/pacific-observatory/data/tourism/vanuatu/temp/2014-TM-12-December-News.csv passed the quality check.\n",
      "/Users/czhang/Desktop/pacific-observatory/data/tourism/vanuatu/temp/IVA_6_June_2019.csv passed the quality check.\n",
      "/Users/czhang/Desktop/pacific-observatory/data/tourism/vanuatu/temp/IAS_12_December_2015.csv passed the quality check.\n",
      "/Users/czhang/Desktop/pacific-observatory/data/tourism/vanuatu/temp/IAS_12_December_2016.csv passed the quality check.\n"
     ]
    }
   ],
   "source": [
    "check_lst = os.listdir(os.getcwd() + \"/data/tourism/vanuatu/temp\")\n",
    "check_lst = [os.getcwd() + \"/data/tourism/vanuatu/temp/\" + file for file in check_lst]\n",
    "\n",
    "for file in check_lst:\n",
    "    if \".DS_Store\" not in file:\n",
    "        df = pd.read_csv(file).drop(\"Unnamed: 0\", axis=1)\n",
    "        df = remove_separator(df)\n",
    "        if check_quality(df, [\"Year\", \"Month\"], \"Visitors\"):\n",
    "            df.to_csv(file, encoding=\"\")\n",
    "        else:\n",
    "            print(f\"{file} fails to pass the quality check.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b243ed43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     108808\n",
       "1      89952\n",
       "2      95117\n",
       "3     109170\n",
       "4     115634\n",
       "5      10315\n",
       "6       9148\n",
       "7       9749\n",
       "8      12283\n",
       "9      10468\n",
       "10      9548\n",
       "11      5835\n",
       "12      7026\n",
       "13      9445\n",
       "14      8359\n",
       "15     10607\n",
       "16     12612\n",
       "17     12275\n",
       "18     11700\n",
       "19     10880\n",
       "20      9860\n",
       "21     12481\n",
       "Name: Visitors, dtype: object"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Visitors\"].str.replace(\"-\", \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c017e7e",
   "metadata": {},
   "source": [
    "### Visitor Arrivals by Usual Country of Residence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "0a578749",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tou12_December_News_2005.pdf {'table_loc': []}\n",
      "  Tou12_December_News_2005.pdf could have column errors\n",
      "Tou12_December_News_2004.pdf {'table_loc': []}\n",
      "  Tou12_December_News_2004.pdf has an error.\n",
      "Tou12_December_News_2007.pdf {'table_loc': [3]}\n",
      "  Tou12_December_News_2007.pdf could have column errors\n",
      "IAS_12_December_2015.pdf {'table_loc': [9]}\n",
      "  IAS_12_December_2015.pdf pass the quality check.\n",
      "2012-TM-12-December_News.pdf {'table_loc': [8]}\n",
      "  2012-TM-12-December_News.pdf could have column errors\n",
      "IAS_12_December_2016.pdf {'table_loc': [9]}\n",
      "  IAS_12_December_2016.pdf pass the quality check.\n",
      "IVA_12_December_2021.pdf {'table_loc': [6]}\n",
      "  IVA_12_December_2021.pdf pass the quality check.\n",
      "2014-TM-12-December-News.pdf {'table_loc': [7]}\n",
      "  2014-TM-12-December-News.pdf pass the quality check.\n",
      "2011-TM-12-December_News.pdf {'table_loc': [6]}\n",
      "  2011-TM-12-December_News.pdf could have column errors\n",
      "2013-TM-12-December_News.pdf {'table_loc': [7]}\n",
      "  2013-TM-12-December_News.pdf could have column errors\n",
      "Tou12_December_2006.pdf {'table_loc': [3]}\n",
      "  Tou12_December_2006.pdf pass the quality check.\n",
      "TM12_December_2009_News.pdf {'table_loc': [4]}\n",
      "  TM12_December_2009_News.pdf could have column errors\n",
      "TM12_December_2008_News.pdf {'table_loc': [3]}\n",
      "  TM12_December_2008_News.pdf could have column errors\n",
      "IVA_12_December-English_2019.pdf {'table_loc': [10]}\n",
      "  IVA_12_December-English_2019.pdf pass the quality check.\n",
      "IAS_12_December_2018.pdf {'table_loc': [8]}\n",
      "  IAS_12_December_2018.pdf pass the quality check.\n",
      "IAS_12_Dececember_2017.pdf {'table_loc': [8]}\n",
      "  IAS_12_Dececember_2017.pdf pass the quality check.\n",
      "2010-TM-12-December_News.pdf {'table_loc': []}\n",
      "  2010-TM-12-December_News.pdf has an error.\n",
      "IVA_12_Dec_2020.pdf {'table_loc': [5]}\n",
      "  IVA_12_Dec_2020.pdf pass the quality check.\n"
     ]
    }
   ],
   "source": [
    "bycountry_err_dict = {\n",
    "    \"file\": [],\n",
    "    \"reason\": []\n",
    "}\n",
    "\n",
    "for file in dec_lst:\n",
    "    filepath = \"/Users/czhang/Desktop/pacific-observatory/data/tourism/vanuatu/\" + file\n",
    "    print(file, locate_table(\n",
    "        filepath, \"Visitor Arrivals by Usual Country of Residence\", ignore_case=True))\n",
    "    try:\n",
    "        df = load_pdf(\n",
    "            filepath, \"Visitor Arrivals by Usual Country of Residence\", 2)\n",
    "        df = df.iloc[:, :-2].dropna(thresh=4, axis=1)\n",
    "\n",
    "        headers, row1 = df.columns.to_list(), df.iloc[0].to_list()\n",
    "        newheader = list()\n",
    "        for header, row in zip(headers, row1):\n",
    "            if type(header) != str:\n",
    "                newheader.append(str(row))\n",
    "            else:\n",
    "                newheader.append(str(header))\n",
    "\n",
    "        newheader[-1] = \"Total\"\n",
    "        newheader[newheader.index(\"Countries\")], newheader[newheader.index(\n",
    "            \"nan\")] = \"Other PIC\", \"Europe\"\n",
    "\n",
    "        df.columns = newheader\n",
    "        df = df.iloc[2:].reset_index().drop(\"index\", axis=1)\n",
    "        df = remove_separator(df)\n",
    "        if check_quality(df, [\"Month\", \"Year\"], \"Total\"):\n",
    "            print(f\"  {file} pass the quality check.\")\n",
    "            saved_path = \"/Users/czhang/Desktop/pacific-observatory/data/tourism/vanuatu/byorigin/\" + \\\n",
    "                file.split(\".\")[0] + \".csv\"\n",
    "            df.to_csv(saved_path, encoding=\"utf-8\")\n",
    "        else:\n",
    "            print(f\"  {file} could have column errors\")\n",
    "            saved_path = \"/Users/czhang/Desktop/pacific-observatory/data/tourism/vanuatu/byorigin/\" + \\\n",
    "                file.split(\".\")[0] + \".csv\"\n",
    "            df.to_csv(saved_path, encoding=\"utf-8\")\n",
    "            bycountry_err_dict[\"file\"].append(file)\n",
    "            bycountry_err_dict[\"reason\"].append(\"Column Error\")\n",
    "    except:\n",
    "        print(f\"  {file} has an error.\")\n",
    "        bycountry_err_dict[\"file\"].append(file)\n",
    "        bycountry_err_dict[\"reason\"].append(\"Missing Error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "71842e5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>reason</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tou12_December_News_2005.pdf</td>\n",
       "      <td>Column Error</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tou12_December_News_2004.pdf</td>\n",
       "      <td>Missing Error</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tou12_December_News_2007.pdf</td>\n",
       "      <td>Column Error</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012-TM-12-December_News.pdf</td>\n",
       "      <td>Column Error</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-TM-12-December_News.pdf</td>\n",
       "      <td>Column Error</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2013-TM-12-December_News.pdf</td>\n",
       "      <td>Column Error</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>TM12_December_2009_News.pdf</td>\n",
       "      <td>Column Error</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>TM12_December_2008_News.pdf</td>\n",
       "      <td>Column Error</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2010-TM-12-December_News.pdf</td>\n",
       "      <td>Missing Error</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           file         reason\n",
       "0  Tou12_December_News_2005.pdf   Column Error\n",
       "1  Tou12_December_News_2004.pdf  Missing Error\n",
       "2  Tou12_December_News_2007.pdf   Column Error\n",
       "3  2012-TM-12-December_News.pdf   Column Error\n",
       "4  2011-TM-12-December_News.pdf   Column Error\n",
       "5  2013-TM-12-December_News.pdf   Column Error\n",
       "6   TM12_December_2009_News.pdf   Column Error\n",
       "7   TM12_December_2008_News.pdf   Column Error\n",
       "8  2010-TM-12-December_News.pdf  Missing Error"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(bycountry_err_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d967914d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import StringIO\n",
    "\n",
    "from pdfminer.converter import TextConverter\n",
    "from pdfminer.layout import LAParams\n",
    "from pdfminer.pdfdocument import PDFDocument\n",
    "from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\n",
    "from pdfminer.pdfpage import PDFPage\n",
    "from pdfminer.pdfparser import PDFParser\n",
    "\n",
    "\n",
    "output_string = StringIO()\n",
    "with open(pdf_path, 'rb') as in_file:\n",
    "    parser = PDFParser(in_file)\n",
    "    doc = PDFDocument(parser)\n",
    "    rsrcmgr = PDFResourceManager()\n",
    "    device = TextConverter(rsrcmgr, output_string, laparams=LAParams())\n",
    "    interpreter = PDFPageInterpreter(rsrcmgr, device)\n",
    "    for page in PDFPage.create_pages(doc):\n",
    "        interpreter.process_page(page)\n",
    "        \n",
    "output_string.getvalue()"
   ]
  }
 ],
 "metadata": {
  "gist": {
   "data": {
    "description": "Desktop/PO-Tourism/parse_demo.ipynb",
    "public": false
   },
   "id": ""
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
